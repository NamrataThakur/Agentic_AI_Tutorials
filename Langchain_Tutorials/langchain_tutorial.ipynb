{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "feb9f1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser, XMLOutputParser\n",
    "from langchain.output_parsers import YamlOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17bdb0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['LANGCHAIN_PROJECT'] = os.getenv('LANGCHAIN_PROJECT')\n",
    "os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = os.getenv('LANGCHAIN_TRACING_V2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dde0150",
   "metadata": {},
   "source": [
    "##### Invoking the model for generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44958bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Namrata! It's nice to meet you. ðŸ˜Š  \n",
      "\n",
      "What can I do for you today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = ChatGroq(model=\"gemma2-9b-it\")\n",
    "print(model.invoke(\"My name is Namrata.\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a1fc3c",
   "metadata": {},
   "source": [
    "##### Creating a chain with prompt and model. Invoking the chain for generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3be9236f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Namrata! \n",
      "\n",
      "It's nice to meet you.  \n",
      "\n",
      "Is there anything specific I can help you with? As an AI engineer, I can assist with a variety of tasks, such as:\n",
      "\n",
      "* **Answering your questions** to the best of my ability based on my training data.\n",
      "* **Generating creative content** like stories, poems, or even code.\n",
      "* **Summarizing text** or providing insights from a given piece of writing.\n",
      "* **Translating languages**.\n",
      "* **And much more!** \n",
      "\n",
      "Just let me know how I can be of service. ðŸ˜Š  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are an expert AI Engineer. Provide me answer based on the question\"),\n",
    "    (\"user\",\"{input}\")\n",
    "])\n",
    "\n",
    "chain = prompt | model\n",
    "result = chain.invoke(input={'input':'My name is Namrata.'})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da2e299",
   "metadata": {},
   "source": [
    "##### Adding different parsers to the chain. Invoking the chain (with parsers) for generation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b27d8b",
   "metadata": {},
   "source": [
    "StrOutputParser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a627ec17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is an open-source platform designed to simplify the process of fine-tuning large language models (LLMs) for specific tasks. \n",
      "\n",
      "Think of it as a toolbox specifically built for tailoring powerful AI models like those from OpenAI (e.g., GPT-3) to your unique needs.\n",
      "\n",
      "Here's a breakdown of what makes Langsmith special:\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "* **User-Friendly Interface:** Langsmith provides a web-based interface that makes fine-tuning accessible even to users without extensive coding experience.\n",
      "* **Streamlined Workflow:** It automates many of the complex steps involved in fine-tuning, simplifying the process and reducing the time and effort required.\n",
      "* **Data Management:** Langsmith helps you manage your training data efficiently, allowing you to upload, format, and split it for fine-tuning.\n",
      "* **Model Selection:** You can choose from a variety of pre-trained LLMs to fine-tune, depending on your specific task and requirements.\n",
      "* **Evaluation and Monitoring:** Langsmith offers tools to evaluate the performance of your fine-tuned models and monitor their progress during training.\n",
      "\n",
      "**Benefits:**\n",
      "\n",
      "* **Customization:** Fine-tune LLMs to excel at specific tasks, such as summarizing text, generating creative content, or answering your questions in a particular style.\n",
      "* **Improved Accuracy:** Achieve better results for your use case compared to using a generic pre-trained model.\n",
      "* **Cost-Effectiveness:** Langsmith can help you fine-tune models more efficiently, potentially reducing the computational resources and costs involved.\n",
      "* **Open-Source Nature:** The platform is open-source, meaning you can contribute to its development, customize it to your needs, and benefit from the collaborative efforts of the community.\n",
      "\n",
      "**In essence, Langsmith empowers you to harness the power of LLMs and tailor them to your specific applications, making advanced AI technology more accessible and practical for a wider range of users.**\n",
      "\n"
     ]
    }
   ],
   "source": [
    "str_op_parser = StrOutputParser()\n",
    "chain = prompt | model | str_op_parser\n",
    "result = chain.invoke(input={'input':'What is Langsmith?'})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db17f151",
   "metadata": {},
   "source": [
    "JsonOutputParser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7a271ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"description\": \"Langsmith is an open-source platform designed to simplify the development and deployment of language models.\",\n",
      "  \"features\": [\n",
      "    \"Streamlined development workflow\",\n",
      "    \"Model training and evaluation tools\",\n",
      "    \"Integration with popular frameworks (e.g., HuggingFace)\",\n",
      "    \"Collaborative environment for model sharing and experimentation\"\n",
      "  ],\n",
      "  \"creator\": \"The Langsmith team\",\n",
      "  \"website\": \"https://www.langsmith.com/\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "#OPTION 1: Provide the output format info in the system prompt itself.\n",
    "\n",
    "prompt_json = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are an expert AI Engineer. Provide me answer based on the question. Response should be in JSON object only.\"),\n",
    "    (\"user\",\"{input}\")\n",
    "])\n",
    "str_op_parser = StrOutputParser()\n",
    "chain = prompt_json | model | str_op_parser\n",
    "result = chain.invoke(input={'input':'What is Langsmith?'})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "089daf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "  input_variables=['input'] input_types={} partial_variables={'format_instruction': 'Return a JSON object.'} template='You are an expert AI Engineer. Provide me answer based on the question. \\n {format_instruction} \\n {input}'\n",
      "\n",
      " {'name': 'Langsmith', 'description': 'Langsmith is an open-source platform for developing, deploying, and managing large language models (LLMs).', 'key_features': ['Modular design allows for easy customization and integration with existing workflows.', 'Supports various LLM architectures and frameworks.', 'Provides tools for fine-tuning, evaluation, and monitoring of LLMs.', 'Offers a user-friendly interface for interacting with LLMs and building applications.', 'Focuses on reproducibility and transparency in LLM development.'], 'website': 'https://www.langsmith.ai/'}\n"
     ]
    }
   ],
   "source": [
    "#OPTION 2: Using the JsonOutputParser to decide the output format, instead of mentioning it explicitely in the system prompt. Using PromptTemplate\n",
    "\n",
    "json_op_parser = JsonOutputParser()\n",
    "output_format = json_op_parser.get_format_instructions()\n",
    "\n",
    "json_prompt = PromptTemplate(\n",
    "    template = \"You are an expert AI Engineer. Provide me answer based on the question. \\n {format_instruction} \\n {input}\",\n",
    "    input_variables=[\"input\"],\n",
    "    partial_variables={'format_instruction':output_format}\n",
    "\n",
    ")\n",
    "print('Prompt:\\n ', json_prompt)\n",
    "\n",
    "chain = json_prompt | model | json_op_parser\n",
    "result = chain.invoke(input={'input':'What is Langsmith?'})\n",
    "print('\\n',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d159ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "  input_variables=['format_instruction', 'input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['format_instruction'], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answer based on the question. \\n {format_instruction}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n",
      "{'name': 'LangSmith', 'description': 'LangSmith is an open-source platform for building and deploying AI models, particularly focused on language models.', 'features': ['Code generation and debugging assistance', 'Text summarization and paraphrasing', 'Dialogue generation and chatbot creation', 'Translation and text classification', 'Fine-tuning existing language models'], 'benefits': ['Easy-to-use interface for both beginners and experts', 'Modular design allows for customization and extensibility', 'Access to a wide range of pre-trained models', 'Collaborative development environment', 'Open-source and community-driven'], 'website': 'https://www.langsmith.com/'}\n"
     ]
    }
   ],
   "source": [
    "#OPTION 3: Using the JsonOutputParser to decide the output format, instead of mentioning it explicitely in the system prompt. Using ChatPromptTemplate\n",
    "\n",
    "json_op_parser = JsonOutputParser()\n",
    "output_format = json_op_parser.get_format_instructions()\n",
    "\n",
    "prompt_json = ChatPromptTemplate.from_messages(\n",
    "    messages=[\n",
    "            (\"system\",\"You are an expert AI Engineer. Provide me answer based on the question. \\n {format_instruction}\"),\n",
    "            (\"user\",\"{input}\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "print('Prompt:\\n ', prompt_json)\n",
    "\n",
    "chain = prompt_json | model | json_op_parser\n",
    "result = chain.invoke(input={'input':'What is Langsmith?','format_instruction':{output_format}})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a220f05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56589aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a41fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed23655b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899e6308",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic_ai_2_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
