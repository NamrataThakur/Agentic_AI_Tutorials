{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "feb9f1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser, XMLOutputParser\n",
    "from langchain.output_parsers import YamlOutputParser\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17bdb0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['LANGCHAIN_PROJECT'] = os.getenv('LANGCHAIN_PROJECT')\n",
    "os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = os.getenv('LANGCHAIN_TRACING_V2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dde0150",
   "metadata": {},
   "source": [
    "##### Invoking the model for generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44958bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Namrata, it's nice to meet you!\n",
      "\n",
      "Is there anything I can help you with today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = ChatGroq(model=\"gemma2-9b-it\")\n",
    "print(model.invoke(\"My name is Namrata.\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a1fc3c",
   "metadata": {},
   "source": [
    "##### Creating a chain with prompt and model. Invoking the chain for generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3be9236f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Namrata! \n",
      "\n",
      "It's nice to meet you.  \n",
      "\n",
      "How can I help you today?  \n",
      "\n",
      "Since you're asking me as an AI Engineer, are you interested in discussing AI technology, machine learning, or perhaps have a specific project in mind? \n",
      "\n",
      "I'm here to assist in any way I can. ðŸ˜Š  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are an expert AI Engineer. Provide me answer based on the question\"),\n",
    "    (\"user\",\"{input}\")\n",
    "])\n",
    "\n",
    "chain = prompt | model\n",
    "result = chain.invoke(input={'input':'My name is Namrata.'})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da2e299",
   "metadata": {},
   "source": [
    "##### Adding different parsers to the chain. Invoking the chain (with parsers) for generation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b27d8b",
   "metadata": {},
   "source": [
    "StrOutputParser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a627ec17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith is an open-source platform developed by AI21 Labs for building and fine-tuning large language models (LLMs).  \n",
      "\n",
      "Here's a breakdown of what makes LangSmith special:\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "* **User-Friendly Interface:**  LangSmith offers a web-based interface that simplifies the process of working with LLMs, even for users without extensive coding experience.\n",
      "* **Fine-Tuning Capabilities:**  It allows you to fine-tune pre-trained LLMs on your own datasets, enabling you to customize the model's behavior and performance for specific tasks.\n",
      "* **Dataset Management:** LangSmith provides tools for managing and annotating your datasets, which is crucial for effective fine-tuning.\n",
      "* **Experiment Tracking:** It helps you track your fine-tuning experiments, compare different model configurations, and identify the best-performing settings.\n",
      "* **Community and Collaboration:** As an open-source platform, LangSmith fosters a community of developers and researchers who can share their models, datasets, and insights.\n",
      "\n",
      "**Benefits:**\n",
      "\n",
      "* **Democratization of AI:** LangSmith makes it easier for individuals and organizations to access and utilize the power of LLMs, regardless of their technical expertise.\n",
      "* **Customization and Specialization:** Fine-tuning allows you to tailor LLMs to your specific needs, such as generating code in a particular programming language, summarizing medical documents, or translating text into a specific dialect.\n",
      "* **Transparency and Reproducibility:** The open-source nature of LangSmith promotes transparency in the development and deployment of LLMs, making it easier to understand how models work and reproduce results.\n",
      "\n",
      "**Who Can Use LangSmith?**\n",
      "\n",
      "* **Researchers:** Explore new applications for LLMs and conduct experiments with different model architectures and training techniques.\n",
      "* **Developers:** Build AI-powered applications that leverage the capabilities of fine-tuned LLMs.\n",
      "* **Businesses:** Customize LLMs for specific business tasks, such as customer service, content creation, or data analysis.\n",
      "* **Educators:** Use LangSmith as a tool for teaching and learning about natural language processing and AI.\n",
      "\n",
      "\n",
      "\n",
      "Let me know if you have any more questions about LangSmith or LLMs in general!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "str_op_parser = StrOutputParser()\n",
    "chain = prompt | model | str_op_parser\n",
    "result = chain.invoke(input={'input':'What is Langsmith?'})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db17f151",
   "metadata": {},
   "source": [
    "JsonOutputParser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7a271ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"name\": \"Langsmith\",\n",
      "  \"description\": \"A platform for building and deploying AI assistants.\",\n",
      "  \"features\": [\n",
      "    \"Allows users to fine-tune pre-trained language models.\",\n",
      "    \"Provides tools for creating conversational interfaces.\",\n",
      "    \"Offers a marketplace for sharing and discovering AI assistants.\",\n",
      "    \"Supports multiple programming languages and frameworks.\"\n",
      "  ],\n",
      "  \"creator\": \"Cohere\"\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#OPTION 1: Provide the output format info in the system prompt itself.\n",
    "\n",
    "prompt_json = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are an expert AI Engineer. Provide me answer based on the question. Response should be in JSON object only.\"),\n",
    "    (\"user\",\"{input}\")\n",
    "])\n",
    "str_op_parser = StrOutputParser()\n",
    "chain = prompt_json | model | str_op_parser\n",
    "result = chain.invoke(input={'input':'What is Langsmith?'})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "089daf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "  input_variables=['input'] input_types={} partial_variables={'format_instruction': 'Return a JSON object.'} template='You are an expert AI Engineer. Provide me answer based on the question. \\n {format_instruction} \\n {input}'\n",
      "\n",
      " {'description': 'Langsmith is an open-source framework designed for building and deploying AI-powered applications with large language models (LLMs).', 'key_features': ['Modular and Extensible Design:', 'Supports Multiple LLMs:', 'Streamlined Development Workflow:', 'Built-in Tools for Evaluation and Monitoring:', 'Focus on Responsible AI Practices'], 'benefits': ['Faster Development Cycles:', 'Improved Model Performance:', 'Enhanced Collaboration:', 'Increased Transparency and Accountability'], 'website': 'https://github.com/langsmith-ai/langsmith'}\n"
     ]
    }
   ],
   "source": [
    "#OPTION 2: Using the JsonOutputParser to decide the output format, instead of mentioning it explicitely in the system prompt. Using PromptTemplate\n",
    "\n",
    "json_op_parser = JsonOutputParser()\n",
    "output_format = json_op_parser.get_format_instructions()\n",
    "\n",
    "json_prompt = PromptTemplate(\n",
    "    template = \"You are an expert AI Engineer. Provide me answer based on the question. \\n {format_instruction} \\n {input}\",\n",
    "    input_variables=[\"input\"],\n",
    "    partial_variables={'format_instruction':output_format}\n",
    "\n",
    ")\n",
    "print('Prompt:\\n ', json_prompt)\n",
    "\n",
    "chain = json_prompt | model | json_op_parser\n",
    "result = chain.invoke(input={'input':'What is Langsmith?'})\n",
    "print('\\n',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d159ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "  input_variables=['format_instruction', 'input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['format_instruction'], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answer based on the question. \\n {format_instruction}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n",
      "{'name': 'Langsmith', 'description': 'Langsmith is an open-source platform for building and deploying AI applications powered by large language models (LLMs).', 'features': ['Modular and composable components for building complex AI workflows', \"Support for multiple LLMs, including OpenAI's GPT models and Hugging Face Transformers\", 'Tools for data preparation, model training, and evaluation', 'Deployment options for cloud, on-premise, and edge devices', 'Open-source and community-driven development'], 'website': 'https://github.com/langsmithai/langsmith'}\n"
     ]
    }
   ],
   "source": [
    "#OPTION 3: Using the JsonOutputParser to decide the output format, instead of mentioning it explicitely in the system prompt. Using ChatPromptTemplate\n",
    "\n",
    "json_op_parser = JsonOutputParser()\n",
    "output_format = json_op_parser.get_format_instructions()\n",
    "\n",
    "prompt_json = ChatPromptTemplate.from_messages(\n",
    "    messages=[\n",
    "            (\"system\",\"You are an expert AI Engineer. Provide me answer based on the question. \\n {format_instruction}\"),\n",
    "            (\"user\",\"{input}\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "print('Prompt:\\n ', prompt_json)\n",
    "\n",
    "chain = prompt_json | model | json_op_parser\n",
    "result = chain.invoke(input={'input':'What is Langsmith?','format_instruction':{output_format}})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1c11ab",
   "metadata": {},
   "source": [
    "Using Pydantic to standardize the LLM outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a220f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Let's talk iPhones!  You're probably interested in the **iPhone 15 series**, the latest and greatest from Apple.  They launched in September 2023 and there are four models to choose from, each with unique features:\n",
      "\n",
      "* **iPhone 15:** The standard model, offering a fantastic balance of performance, features, and price. It boasts a powerful A16 Bionic chip, a vibrant 6.1-inch Super Retina XDR display, and a dual-camera system with impressive low-light capabilities. Starting at **$799**.\n",
      "\n",
      "* **iPhone 15 Plus:**  For those who want a bigger screen, this model features a spacious 6.7-inch display, the same A16 Bionic chip, and a dual-camera system. It starts at **$899**.\n",
      "\n",
      "* **iPhone 15 Pro:** This is where things get really exciting. It features a next-generation A17 Pro chip, a stunning 6.1-inch Super Retina XDR display with a ProMotion refresh rate up to 120Hz, and a triple-camera system with a new 48MP main sensor and LiDAR scanner for advanced photography and augmented reality experiences. Starting at **$999**.\n",
      "\n",
      "* **iPhone 15 Pro Max:** The top-of-the-line model with the largest display (6.7-inch), the A17 Pro chip, the advanced triple-camera system, and a longer battery life. It starts at **$1099**.\n",
      "\n",
      "**Here are some key highlights of the iPhone 15 series:**\n",
      "\n",
      "* **USB-C Charging:**  All models now feature USB-C for faster charging and data transfer.\n",
      "* **Titanium Frame:** The Pro models sport a durable and lightweight titanium frame.\n",
      "* **Dynamic Island:** This interactive notch area continues to evolve, offering more functionality and information.\n",
      "* **Action Button:** The Pro models replace the mute switch with a customizable Action button, allowing you to quickly access various features.\n",
      "\n",
      "**Interested in learning more about a specific model or feature?** Let me know, and I'd be happy to provide more details!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using StrOutputParser:\n",
    "\n",
    "class Product(BaseModel):\n",
    "\n",
    "    product_name :str = Field(description=\"name of the product\")\n",
    "    price : int = Field(description=\"tentative price in USD\")\n",
    "\n",
    "str_parser = StrOutputParser(pydantic_object=Product)\n",
    "\n",
    "product_prompt = ChatPromptTemplate.from_messages([\n",
    "\n",
    "    (\"system\", \"You are expert Sales person who has vast knowledge on any product and it's description. You are well versed in product names and their prices.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "]\n",
    "\n",
    ")\n",
    "\n",
    "chain = product_prompt | model | str_parser\n",
    "result = chain.invoke(input={'input':'Tell me about the latest iPhone.'})\n",
    "print('\\n',result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb26d0a",
   "metadata": {},
   "source": [
    "Using just the pydantic object in the Parser is not enough. We need to provide the formating instructions too in the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56589aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " {'product_name': 'iPhone 15 Pro Max', 'price': 1099}\n"
     ]
    }
   ],
   "source": [
    "#Using JsonOutputParser and Prompt Template:\n",
    "\n",
    "class Product(BaseModel):\n",
    "\n",
    "    product_name :str = Field(description=\"name of the product\")\n",
    "    price : int = Field(description=\"tentative price in USD\")\n",
    "\n",
    "str_parser = JsonOutputParser(pydantic_object=Product)\n",
    "output_format = str_parser.get_format_instructions()\n",
    "\n",
    "product_prompt = PromptTemplate(\n",
    "    template = \"You are expert sales person who has vast knowledge on any product and it's price. Provide an answer to the question. \\n {format_instruction} \\n {input}\",\n",
    "    input_variables=[\"input\"],\n",
    "    partial_variables={'format_instruction':output_format}\n",
    "\n",
    ")\n",
    "\n",
    "chain = product_prompt | model | str_parser\n",
    "result = chain.invoke(input={'input':'Tell me about the latest iPhone.'})\n",
    "print('\\n',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05a41fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " {'product_name': 'iPhone 15 Pro Max', 'price': 1099}\n"
     ]
    }
   ],
   "source": [
    "#Using JsonOutputParser and ChatPrompt Template:\n",
    "\n",
    "class Product(BaseModel):\n",
    "\n",
    "    product_name :str = Field(description=\"name of the product\")\n",
    "    price : int = Field(description=\"tentative price in USD\")\n",
    "\n",
    "str_parser = JsonOutputParser(pydantic_object=Product)\n",
    "output_format = str_parser.get_format_instructions()\n",
    "\n",
    "product_prompt = ChatPromptTemplate.from_messages(\n",
    "    messages=[\n",
    "            (\"system\",\"You are expert sales person who has vast knowledge on any product and it's price. Provide an answer to the question. \\n {format_instruction}\"),\n",
    "            (\"user\",\"{input}\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "chain = product_prompt | model | str_parser\n",
    "result = chain.invoke(input={'input':'Tell me about the latest iPhone.', 'format_instruction':output_format})\n",
    "print('\\n',result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248ba8c6",
   "metadata": {},
   "source": [
    "Using Pydantic we can thus standardize the output of the LLMs. The output will always come using only the information required according to the pydantic class object passed to the parser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bbca5b",
   "metadata": {},
   "source": [
    "Using Pydantic model on YamlOutputParser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed23655b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " product_name='iPhone 15 Pro Max' price=1099\n"
     ]
    }
   ],
   "source": [
    "#Using YamlOutputParser and Prompt Template:\n",
    "\n",
    "class Product(BaseModel):\n",
    "\n",
    "    product_name :str = Field(description=\"name of the product\")\n",
    "    price : int = Field(description=\"tentative price in USD\")\n",
    "\n",
    "str_parser = YamlOutputParser(pydantic_object=Product)\n",
    "output_format = str_parser.get_format_instructions()\n",
    "\n",
    "product_prompt = PromptTemplate(\n",
    "    template = \"You are expert sales person who has vast knowledge on any product and it's price. Provide an answer to the question. \\n {format_instruction} \\n {input}\",\n",
    "    input_variables=[\"input\"],\n",
    "    partial_variables={'format_instruction':output_format}\n",
    "\n",
    ")\n",
    "\n",
    "chain = product_prompt | model | str_parser\n",
    "result = chain.invoke(input={'input':'Tell me about the latest iPhone.'})\n",
    "print('\\n',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899e6308",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic_ai_2_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
